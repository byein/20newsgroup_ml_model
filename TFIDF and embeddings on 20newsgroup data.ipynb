{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import utils\n",
    "import numpy as np\n",
    "import sys\n",
    "from nltk import word_tokenize\n",
    "from nltk import download\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import string\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r',encoding=\"utf8\")\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_embedding(model,sentence):\n",
    "    doc1 = [word for word in doc if word in model.keys()]\n",
    "    sent_emb = np.mean([model[t] if t in model else model['unk'] for t in doc1 ],axis=0)\n",
    "    return sent_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier, X, y):\n",
    "    start = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"Accuracy: \" + str(classifier.score(X_test, y_test)) + \", Time duration: \" + str(end - start))\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "(18846, 173618)\n"
     ]
    }
   ],
   "source": [
    "#fitting newsdata in tfidf\n",
    "vectorizer = TfidfVectorizer( stop_words=stopwords.words('english') + list(string.punctuation))\n",
    "fit = vectorizer.fit_transform(news.data)\n",
    "print(type(news.data))\n",
    "print(fit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=40, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=11, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LinearSVC(C=40,random_state=11)\n",
    "targets = news.target\n",
    "classifier.fit(fit, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9336870026525199, Time duration: 64.79490399360657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=40, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=11, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(classifier,fit,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing news data for glove embeddings\n",
    "processed_docs = []\n",
    "\n",
    "for doc in news.data:\n",
    "    processed_docs.append(preprocess(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\\nSubject: Pens fans reactions\\nOrganization: Post Office, Carnegie Mellon, Pittsburgh, PA\\nLines: 12\\nNNTP-Posting-Host: po4.andrew.cmu.edu\\n\\n\\n\\nI am sure some bashers of Pens fans are pretty confused about the lack\\nof any kind of posts about the recent Pens massacre of the Devils. Actually,\\nI am  bit puzzled too and a bit relieved. However, I am going to put an end\\nto non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\\nare killing those Devils worse than I thought. Jagr just showed you why\\nhe is much better than his regular season stats. He is also a lot\\nfo fun to watch in the playoffs. Bowman should let JAgr have a lot of\\nfun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\\nregular season game.          PENS RULE!!!\\n\\n\", 'From: mblawson@midway.ecn.uoknor.edu (Matthew B Lawson)\\nSubject: Which high-performance VLB video card?\\nSummary: Seek recommendations for VLB video card\\nNntp-Posting-Host: midway.ecn.uoknor.edu\\nOrganization: Engineering Computer Network, University of Oklahoma, Norman, OK, USA\\nKeywords: orchid, stealth, vlb\\nLines: 21\\n\\n  My brother is in the market for a high-performance video card that supports\\nVESA local bus with 1-2MB RAM.  Does anyone have suggestions/ideas on:\\n\\n  - Diamond Stealth Pro Local Bus\\n\\n  - Orchid Farenheit 1280\\n\\n  - ATI Graphics Ultra Pro\\n\\n  - Any other high-performance VLB card\\n\\n\\nPlease post or email.  Thank you!\\n\\n  - Matt\\n\\n-- \\n    |  Matthew B. Lawson <------------> (mblawson@essex.ecn.uoknor.edu)  |   \\n  --+-- \"Now I, Nebuchadnezzar, praise and exalt and glorify the King  --+-- \\n    |   of heaven, because everything he does is right and all his ways  |   \\n    |   are just.\" - Nebuchadnezzar, king of Babylon, 562 B.C.           |   \\n']\n",
      "[['mamatha', 'devineni', 'ratnam', 'andrew', 'subject', 'pen', 'fan', 'reaction', 'organ', 'post', 'offic', 'carnegi', 'mellon', 'pittsburgh', 'line', 'nntp', 'post', 'host', 'andrew', 'sure', 'basher', 'pen', 'fan', 'pretti', 'confus', 'lack', 'kind', 'post', 'recent', 'pen', 'massacr', 'devil', 'actual', 'puzzl', 'reliev', 'go', 'pittsburgh', 'relief', 'prais', 'pen', 'kill', 'devil', 'wors', 'think', 'jagr', 'show', 'better', 'regular', 'season', 'stat', 'watch', 'playoff', 'bowman', 'jagr', 'coupl', 'game', 'pen', 'go', 'beat', 'pulp', 'jersey', 'disappoint', 'island', 'lose', 'final', 'regular', 'season', 'game', 'pen', 'rule'], ['mblawson', 'midway', 'uoknor', 'matthew', 'lawson', 'subject', 'high', 'perform', 'video', 'card', 'summari', 'seek', 'recommend', 'video', 'card', 'nntp', 'post', 'host', 'midway', 'uoknor', 'organ', 'engin', 'network', 'univers', 'oklahoma', 'norman', 'keyword', 'orchid', 'stealth', 'line', 'brother', 'market', 'high', 'perform', 'video', 'card', 'support', 'vesa', 'local', 'suggest', 'idea', 'diamond', 'stealth', 'local', 'orchid', 'farenheit', 'graphic', 'ultra', 'high', 'perform', 'card', 'post', 'email', 'thank', 'matt', 'matthew', 'lawson', 'mblawson', 'essex', 'uoknor', 'nebuchadnezzar', 'prais', 'exalt', 'glorifi', 'king', 'heaven', 'right', 'way', 'nebuchadnezzar', 'king', 'babylon']]\n"
     ]
    }
   ],
   "source": [
    "#just checking whether preprocessing went good \n",
    "print(news.data[:2])\n",
    "print(processed_docs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "#loading glove 300d model\n",
    "model=load_glove_model(\"E:/Genesis/glove.6B/glove.6B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look up each doc in model\n",
    "embeddings =[]\n",
    "for doc in processed_docs: \n",
    "    embeddings.append(sent_embedding(model, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.21768983e-02,  1.91594415e-01,  4.73643678e-02, -1.19968824e-01,\n",
       "        3.80117119e-02,  6.53641288e-02, -1.10010983e-01, -1.18436051e-01,\n",
       "        1.43357983e-02, -6.46838392e-01,  6.71145102e-02, -7.81769000e-02,\n",
       "       -3.94446780e-02,  1.70745763e-03,  1.29294576e-01,  1.27127034e-01,\n",
       "       -1.01492898e-01, -1.45242034e-02,  6.80205085e-03, -2.95049322e-02,\n",
       "        5.28671593e-02, -6.70104576e-02,  2.88601288e-02, -4.07195492e-02,\n",
       "       -4.38682542e-02,  5.49512542e-02,  6.45782610e-02, -5.96864105e-02,\n",
       "        1.35152871e-01, -3.59614407e-03,  2.82939424e-02, -3.27766102e-03,\n",
       "       -2.27027288e-02, -2.44179661e-02, -9.11055593e-01, -7.60123220e-03,\n",
       "       -1.97699644e-02,  1.49644068e-01, -3.85641186e-03, -2.80517186e-02,\n",
       "        2.72594576e-02, -6.03006780e-03, -4.19913220e-02, -6.23525254e-02,\n",
       "       -8.95754203e-02,  1.44762702e-01,  8.09564551e-02,  7.61392847e-02,\n",
       "       -7.53171068e-02,  9.25236908e-02, -3.16560458e-02,  1.18373492e-01,\n",
       "        7.17933088e-02, -2.61090339e-02, -7.18067339e-02,  1.79429690e-01,\n",
       "        2.39604559e-02,  7.58239153e-02,  1.27162929e-01, -1.03400390e-01,\n",
       "       -5.38794237e-02,  8.76284068e-02, -1.27307458e-03,  2.39901407e-02,\n",
       "       -3.72919254e-02, -2.41357085e-01,  6.16011864e-02,  3.85611573e-02,\n",
       "        1.20947695e-01, -1.95311678e-02,  2.12125488e-01,  2.87680339e-02,\n",
       "       -2.49497627e-03,  1.46646271e-01, -6.06032847e-02, -2.69178271e-02,\n",
       "        7.00485997e-02,  8.48863051e-02, -4.65452034e-02,  6.39246949e-03,\n",
       "        6.99493288e-03,  3.69103729e-02, -4.11508864e-02, -1.45522114e-01,\n",
       "       -1.11201695e-03,  4.40980847e-02, -8.49695898e-02,  7.65756610e-02,\n",
       "       -9.51783780e-02, -3.21549475e-02, -3.41928492e-02,  6.45630966e-02,\n",
       "       -4.14896627e-02, -2.23302000e-01, -7.62861271e-02,  5.64709932e-02,\n",
       "       -4.62020169e-02, -3.59388475e-03, -4.56684102e-02, -3.16156627e-01,\n",
       "        2.41908881e-02,  7.31690678e-02, -8.82653898e-03, -8.44850847e-03,\n",
       "        3.50689120e-02,  1.67193220e-02,  5.20204746e-03,  9.66268576e-02,\n",
       "       -4.66696780e-02,  1.60752685e-01, -7.71673542e-02, -8.25520119e-02,\n",
       "       -8.39438620e-02, -4.94139153e-02,  8.70606780e-03,  4.51498525e-02,\n",
       "       -6.59353339e-02,  7.43216003e-02,  1.49137288e-03, -1.74691702e-01,\n",
       "       -3.98618898e-02, -8.39433746e-02,  7.05999553e-02,  1.08669122e-01,\n",
       "        6.82907068e-02, -1.16597847e-02, -1.75319661e-03, -2.45856559e-02,\n",
       "        7.49769746e-03, -3.61321644e-02,  1.42158834e-01,  1.28209231e-01,\n",
       "       -7.27017559e-02, -9.77803525e-02, -1.19003898e-02,  1.99856576e-02,\n",
       "        5.78152881e-03, -5.72280831e-02,  1.53521390e-01,  7.43020678e-02,\n",
       "       -1.91986390e-02,  6.06818983e-02, -8.63972678e-02,  6.85711119e-02,\n",
       "       -6.25661458e-02,  1.50908492e-01, -7.44558603e-02, -2.40704746e-02,\n",
       "        3.79473051e-03,  3.26220847e-03,  1.51507824e-01, -3.87286949e-02,\n",
       "       -6.02894542e-02, -1.82576390e-01,  1.72772305e-01, -4.06638373e-02,\n",
       "       -3.01402898e-02,  2.01215254e-02,  2.19028424e-02, -3.03409305e-02,\n",
       "       -1.02353729e-02, -3.03273898e-02, -7.72454525e-02, -1.24014261e-01,\n",
       "       -1.04611525e-03,  2.26355380e-01, -2.04022424e-02,  5.93832542e-03,\n",
       "       -1.88332593e-01,  1.94689661e-02,  1.83327271e-02, -1.51329831e-02,\n",
       "       -5.17940559e-01,  4.73408475e-03, -5.65808475e-02, -6.24248780e-02,\n",
       "        8.57102169e-02,  9.36722712e-02,  3.23974068e-02,  1.71508831e-01,\n",
       "        1.71752263e-01,  1.03488819e-01,  2.08906186e-01,  2.89093729e-02,\n",
       "       -6.91525153e-02, -1.61419661e-02, -1.33761763e-01, -2.16713051e-02,\n",
       "        2.67248136e-03,  1.35992102e-01, -3.47138983e-02,  1.64657017e-01,\n",
       "        1.14402061e-01, -6.88236627e-02,  3.95082763e-02, -7.33228407e-02,\n",
       "        2.05738136e-02, -1.45793898e-02,  1.21480564e-01,  8.01864746e-03,\n",
       "        8.31110797e-01,  1.31639813e-01,  3.58532339e-02, -4.79076102e-02,\n",
       "        4.22098102e-02, -8.95062576e-02,  3.49990085e-02, -2.05592203e-02,\n",
       "       -1.35886634e-01, -4.68606271e-02, -8.30943898e-02,  7.06695424e-03,\n",
       "        1.18347339e-01,  3.10468169e-02, -2.29372559e-02, -1.54317322e-01,\n",
       "       -5.84641695e-02,  4.14087973e-02, -1.00018034e-02, -1.27037161e-01,\n",
       "       -8.92039207e-02,  1.10629271e-02, -5.00925610e-02,  3.74604881e-02,\n",
       "       -2.57226271e-03, -1.33121958e-01,  5.03763729e-02,  9.19412451e-02,\n",
       "        2.04805708e-02, -1.19395402e-01, -2.89883824e-02,  8.15197000e-02,\n",
       "       -6.47154746e-02, -7.63363593e-02, -2.54497102e-02,  3.95708983e-02,\n",
       "       -6.75317847e-02,  1.04369139e-01,  1.69708678e-02,  9.78107627e-02,\n",
       "        4.09152780e-02, -1.15297433e-01,  7.11130915e-02,  4.15819576e-02,\n",
       "       -2.35916458e-01,  2.10035593e-03, -4.66550000e-02,  1.26206412e-01,\n",
       "       -1.67917797e-02, -6.98695458e-02,  1.00212876e-01, -8.83683153e-02,\n",
       "       -2.29486186e-02,  1.04864000e-01,  2.09842254e-01,  3.42672203e-03,\n",
       "        2.02569305e-01, -1.90130237e-01, -1.05285475e-02, -8.29272356e-02,\n",
       "       -9.85449831e-02, -5.61649661e-02, -8.09096898e-02, -2.27167322e-02,\n",
       "       -3.29708661e-02, -5.92647966e-02, -5.36492237e-02,  1.07070119e-01,\n",
       "       -4.32211051e-02,  1.48047627e-02,  7.04479034e-02, -7.02246373e-02,\n",
       "        9.33143881e-02, -2.13793458e-01,  1.09090861e-01,  5.18151881e-02,\n",
       "       -1.16192627e+00,  2.28534678e-02,  4.24683390e-02,  1.19050726e-01,\n",
       "       -1.17365169e-01,  6.60200968e-02,  1.46888305e-02,  1.52198254e-02,\n",
       "       -3.90467220e-02,  8.61339831e-02,  7.81983456e-02,  4.05296610e-03,\n",
       "       -6.53307563e-02,  2.21545661e-02, -7.46692017e-02,  1.23539763e-02,\n",
       "       -1.21829446e-01,  8.85880000e-02,  7.07226441e-02,  6.45786000e-02,\n",
       "        5.03769831e-02, -4.97590678e-02,  9.80077983e-02,  1.13033190e-01])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how does embedding look for one doc\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_emb = LinearSVC(C=40, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7342175066312997, Time duration: 210.19688820838928\n"
     ]
    }
   ],
   "source": [
    "classifier_emb=train(classifier_emb, embeddings, news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9336870026525199, Time duration: 90.04454851150513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=... max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=11, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidif has way better accuracy then glove embeddings so pipelining tfidf\n",
    "tfidfclassifier = Pipeline([ ('vectorizer', TfidfVectorizer( stop_words=stopwords.words('english') + list(string.punctuation))), ('classifier', LinearSVC(C=40,random_state=11))])\n",
    "\n",
    "train(tfidfclassifier, news.data, news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidfclassifier, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL = pickle.load( open('model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_news(model, news_str, newscategory):\n",
    "    prediction=newscategory[model.predict([news_str])[0]]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "test_str=\"India scored 3 goals against germany yesterday!\"\n",
    "result = predict_news(MODEL, test_str, news.target_names)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
